#!/usr/bin/env python3
"""
ğŸ”¥ íšŒì˜ë¡ ìë™ íŒŒì‹± & Holon ìƒì„±ê¸°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê¸°ëŠ¥:
- íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ Holon ë¬¸ì„œ ìƒì„±
- ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ parent ìë™ ì„ íƒ
- Decision, Task í•­ëª© ìë™ ì¶”ì¶œ
"""

import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple


class MeetingParser:
    """íšŒì˜ë¡ íŒŒì‹± ë° Holon ìë™ ìƒì„±"""
    
    # í‚¤ì›Œë“œ â†’ parent ë§¤í•‘
    KEYWORD_PARENT_MAP = {
        # ì œí’ˆ/ê¸°ìˆ  ê´€ë ¨
        "api": "hte-doc-005",
        "ì‹œìŠ¤í…œ": "hte-doc-002",
        "ì•„í‚¤í…ì²˜": "hte-doc-002",
        "ì œí’ˆ": "hte-doc-002",
        "ê¸°ëŠ¥": "hte-doc-002",
        "ê°œë°œ": "hte-doc-002",
        
        # ì¡°ì§ ê´€ë ¨
        "ì¡°ì§": "hte-doc-001",
        "íŒ€": "hte-doc-001",
        "ì¸ì‚¬": "hte-doc-001",
        "ì±„ìš©": "hte-doc-001",
        
        # ì „ëµ ê´€ë ¨
        "ì „ëµ": "hte-doc-003",
        "ìš´ì˜": "hte-doc-003",
        "í”„ë¡œì„¸ìŠ¤": "hte-doc-003",
        
        # íˆ¬ì/ì¬ë¬´
        "íˆ¬ì": "hte-doc-004",
        "ì¬ë¬´": "hte-doc-004",
        "ë¹„ìš©": "hte-doc-004",
        "ì˜ˆì‚°": "hte-doc-004",
        
        # AI/PM
        "ai": "strategy-2025-001",
        "pm": "strategy-2025-001",
        "ìë™í™”": "strategy-2025-001",
        "í•™ìƒ": "strategy-2025-001",
        "ì§„ë‹¨": "feature-2025-001",
        "ì‹œì„ ": "feature-2025-002",
        "ì§‘ì¤‘ë„": "feature-2025-002",
    }
    
    # Decision/Task ì¶”ì¶œ íŒ¨í„´
    DECISION_PATTERNS = [
        r"ê²°ì •[:\s]*(.+?)(?:\n|$)",
        r"í•©ì˜[:\s]*(.+?)(?:\n|$)",
        r"í™•ì •[:\s]*(.+?)(?:\n|$)",
        r"â†’\s*ê²°ì •[:\s]*(.+?)(?:\n|$)",
    ]
    
    TASK_PATTERNS = [
        r"í• ì¼[:\s]*(.+?)(?:\n|$)",
        r"TODO[:\s]*(.+?)(?:\n|$)",
        r"ì•¡ì…˜[:\s]*(.+?)(?:\n|$)",
        r"ë‹´ë‹¹[:\s]*(.+?)(?:\n|$)",
        r"â†’\s*(.+?)\s*ë‹´ë‹¹",
        r"\[\s*\]\s*(.+?)(?:\n|$)",  # [ ] ì²´í¬ë°•ìŠ¤
    ]
    
    def __init__(self, holons_path: str):
        self.holons_path = Path(holons_path)
        self.meetings_path = self.holons_path.parent / "meetings"
        self.decisions_path = self.holons_path.parent / "decisions"
        self.tasks_path = self.holons_path.parent / "tasks"
        
        # í´ë” ìƒì„±
        self.meetings_path.mkdir(exist_ok=True)
        self.decisions_path.mkdir(exist_ok=True)
        self.tasks_path.mkdir(exist_ok=True)
        
        # ê¸°ì¡´ Holon ë¡œë“œ
        self.holons = self._load_holons()
    
    def _load_holons(self) -> Dict[str, dict]:
        """ê¸°ì¡´ Holon ë¬¸ì„œ ë¡œë“œ"""
        holons = {}
        for md_file in self.holons_path.glob("*.md"):
            if md_file.name.startswith("_"):
                continue
            content = md_file.read_text(encoding="utf-8")
            json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
            if json_match:
                try:
                    holon = json.loads(json_match.group(1))
                    holon_id = holon.get("holon_id")
                    if holon_id:
                        holons[holon_id] = holon
                except:
                    pass
        return holons
    
    def _extract_title(self, text: str) -> str:
        """íšŒì˜ë¡ì—ì„œ ì œëª© ì¶”ì¶œ"""
        lines = text.strip().split("\n")
        
        # ì²« ì¤„ì´ ì œëª©ì¼ ê°€ëŠ¥ì„±
        first_line = lines[0].strip()
        
        # # ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ë§ˆí¬ë‹¤ìš´ ì œëª©
        if first_line.startswith("#"):
            return first_line.lstrip("#").strip()
        
        # ì œëª©: íŒ¨í„´
        title_match = re.search(r"ì œëª©[:\s]*(.+?)(?:\n|$)", text)
        if title_match:
            return title_match.group(1).strip()
        
        # íšŒì˜ëª…: íŒ¨í„´
        meeting_match = re.search(r"íšŒì˜ëª…[:\s]*(.+?)(?:\n|$)", text)
        if meeting_match:
            return meeting_match.group(1).strip()
        
        # ì²« ì¤„ ì‚¬ìš© (30ì ì œí•œ)
        return first_line[:30] if first_line else "íšŒì˜ë¡"
    
    def _extract_date(self, text: str) -> str:
        """íšŒì˜ë¡ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        # YYYY-MM-DD íŒ¨í„´
        date_match = re.search(r"(\d{4}-\d{2}-\d{2})", text)
        if date_match:
            return date_match.group(1)
        
        # YYYY.MM.DD íŒ¨í„´
        date_match = re.search(r"(\d{4})\.(\d{2})\.(\d{2})", text)
        if date_match:
            return f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        return datetime.now().strftime("%Y-%m-%d")
    
    def _extract_participants(self, text: str) -> List[str]:
        """ì°¸ì„ì ì¶”ì¶œ"""
        participants = []
        
        # ì°¸ì„ì: íŒ¨í„´
        match = re.search(r"ì°¸ì„ì?[:\s]*(.+?)(?:\n|$)", text)
        if match:
            names = re.split(r"[,ï¼Œã€\s]+", match.group(1))
            participants = [n.strip() for n in names if n.strip()]
        
        return participants if participants else ["ë¯¸ì§€ì •"]
    
    def _find_best_parent(self, text: str) -> Tuple[str, float]:
        """ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ parent ì°¾ê¸°"""
        text_lower = text.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scores = {}
        for keyword, parent_id in self.KEYWORD_PARENT_MAP.items():
            if keyword in text_lower:
                scores[parent_id] = scores.get(parent_id, 0) + 1
        
        if scores:
            best_parent = max(scores, key=scores.get)
            confidence = scores[best_parent] / len(self.KEYWORD_PARENT_MAP)
            return best_parent, min(confidence * 5, 1.0)  # ìµœëŒ€ 1.0
        
        # ê¸°ë³¸ê°’: strategy-2025-001 (AI PM)
        return "strategy-2025-001", 0.3
    
    def _extract_decisions(self, text: str) -> List[str]:
        """ê²°ì • ì‚¬í•­ ì¶”ì¶œ"""
        decisions = []
        for pattern in self.DECISION_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            decisions.extend([m.strip() for m in matches if m.strip()])
        return list(set(decisions))  # ì¤‘ë³µ ì œê±°
    
    def _extract_tasks(self, text: str) -> List[str]:
        """í• ì¼ ì¶”ì¶œ"""
        tasks = []
        for pattern in self.TASK_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            tasks.extend([m.strip() for m in matches if m.strip()])
        return list(set(tasks))  # ì¤‘ë³µ ì œê±°
    
    def _extract_agenda(self, text: str) -> List[str]:
        """ì•ˆê±´ ì¶”ì¶œ"""
        agenda = []
        
        # ì•ˆê±´: íŒ¨í„´
        agenda_match = re.search(r"ì•ˆê±´[:\s]*\n?((?:.+\n?)+)", text)
        if agenda_match:
            items = agenda_match.group(1).split("\n")
            for item in items:
                item = item.strip()
                if item and not item.startswith(("ì°¸ì„", "ì¼ì‹œ", "ì¥ì†Œ")):
                    # ë²ˆí˜¸/ë¶ˆë¦¿ ì œê±°
                    item = re.sub(r"^[\d\.\-\*\â€¢]+\s*", "", item)
                    if item:
                        agenda.append(item)
        
        return agenda[:5]  # ìµœëŒ€ 5ê°œ
    
    def _generate_meeting_id(self) -> str:
        """íšŒì˜ ID ìƒì„±"""
        today = datetime.now()
        year = today.strftime("%Y")
        
        # ê¸°ì¡´ meeting ê°œìˆ˜ í™•ì¸
        existing = list(self.meetings_path.glob(f"meeting-{year}-*.md"))
        next_num = len(existing) + 1
        
        return f"meeting-{year}-{next_num:03d}"
    
    def _create_meeting_holon(self, text: str) -> dict:
        """íšŒì˜ë¡ í…ìŠ¤íŠ¸ë¡œ Meeting Holon ìƒì„±"""
        title = self._extract_title(text)
        date = self._extract_date(text)
        participants = self._extract_participants(text)
        parent_id, confidence = self._find_best_parent(text)
        decisions = self._extract_decisions(text)
        tasks = self._extract_tasks(text)
        agenda = self._extract_agenda(text)
        meeting_id = self._generate_meeting_id()
        
        # Root W ê°€ì ¸ì˜¤ê¸°
        root_w = self.holons.get("hte-doc-000", {}).get("W", {})
        root_drive = root_w.get("will", {}).get("drive", "")
        
        holon = {
            "holon_id": meeting_id,
            "slug": title.replace(" ", "-").lower()[:30],
            "type": "meeting",
            "module": "M02_TimelineGenesis",
            "meta": {
                "title": title,
                "owner": participants[0] if participants else "ë¯¸ì§€ì •",
                "created_at": date,
                "updated_at": date,
                "priority": "high",
                "status": "active"
            },
            "W": {
                "worldview": {
                    "identity": "íšŒì˜ë¥¼ í†µí•´ ì˜ì‚¬ê²°ì •ê³¼ ë°©í–¥ ì •ë ¬ì„ ìˆ˜í–‰í•˜ëŠ” í˜‘ì—… ì„¸ì…˜",
                    "belief": "íš¨ê³¼ì ì¸ íšŒì˜ëŠ” ëª…í™•í•œ ê²°ì •ê³¼ ì‹¤í–‰ ê°€ëŠ¥í•œ íƒœìŠ¤í¬ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤",
                    "value_system": "ì‹œê°„ íš¨ìœ¨, ê²°ì • ëª…í™•ì„±, ì‹¤í–‰ ì—°ê²°"
                },
                "will": {
                    "drive": f"ì´ íšŒì˜ë¥¼ í†µí•´ {title} ê´€ë ¨ ëª…í™•í•œ ê²°ì •ì„ ë‚´ë¦¬ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•œë‹¤. {root_drive[:50]}...",
                    "commitment": "ëª¨ë“  ì•ˆê±´ì— ëŒ€í•´ ê²°ë¡ ì„ ë‚´ë¦¬ê³  ë‹´ë‹¹ìë¥¼ ì§€ì •í•œë‹¤",
                    "non_negotiables": ["ê²°ì • ì‚¬í•­ ë¬¸ì„œí™”", "ë‹´ë‹¹ì ì§€ì •", "ê¸°í•œ ì„¤ì •"]
                },
                "intention": {
                    "primary": title,
                    "secondary": agenda[:3] if agenda else ["ì•ˆê±´ ë…¼ì˜"],
                    "constraints": ["ì‹œê°„ ì œí•œ", "ì°¸ì„ì ì¼ì •"]
                },
                "goal": {
                    "ultimate": f"{title} ì™„ë£Œ ë° í›„ì† ì¡°ì¹˜ í™•ì •",
                    "milestones": ["ì•ˆê±´ ë…¼ì˜", "ê²°ì •", "ì•¡ì…˜ ì•„ì´í…œ ë„ì¶œ"],
                    "kpi": [f"ê²°ì • {len(decisions)}ê±´", f"íƒœìŠ¤í¬ {len(tasks)}ê±´"],
                    "okr": {
                        "objective": title,
                        "key_results": decisions[:3] if decisions else ["ê²°ì • ì‚¬í•­ ë„ì¶œ"]
                    }
                },
                "activation": {
                    "triggers": ["íšŒì˜ ì‹œì‘"],
                    "resonance_check": f"ìƒìœ„ ëª©í‘œ({parent_id})ì™€ ì •ë ¬ í™•ì¸ë¨ (ì‹ ë¢°ë„: {confidence:.0%})",
                    "drift_detection": "íšŒì˜ ëª©ì ì—ì„œ ë²—ì–´ë‚˜ëŠ” ë…¼ì˜ ê°ì§€"
                }
            },
            "X": {
                "context": text[:500] + "..." if len(text) > 500 else text,
                "current_state": "íšŒì˜ ì™„ë£Œ",
                "heartbeat": "once",
                "signals": ["íšŒì˜ë¡ ì‘ì„±ë¨"],
                "constraints": ["ì°¸ì„ì ì¼ì •", "ì‹œê°„ ì œí•œ"],
                "will": "íšŒì˜ ë§¥ë½ì„ ì •í™•íˆ ê¸°ë¡í•˜ì—¬ í›„ì† ì¡°ì¹˜ì— í™œìš©í•œë‹¤"
            },
            "S": {
                "resources": [
                    {"type": "human", "id": p, "role": "ì°¸ì„ì"} for p in participants
                ],
                "dependencies": [parent_id],
                "access_points": ["ì´ ë¬¸ì„œ"],
                "structure_model": "íšŒì˜ â†’ ê²°ì • â†’ íƒœìŠ¤í¬",
                "ontology_ref": ["M02_TimelineGenesis"],
                "readiness_score": 1.0,
                "will": "í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ë³´í•˜ì—¬ íšŒì˜ ëª©ì ì„ ë‹¬ì„±í•œë‹¤"
            },
            "P": {
                "procedure_steps": [
                    {"step_id": "p001", "description": "ì•ˆê±´ ê²€í† ", "status": "done"},
                    {"step_id": "p002", "description": "ë…¼ì˜ ì§„í–‰", "status": "done"},
                    {"step_id": "p003", "description": "ê²°ì • ë„ì¶œ", "status": "done"},
                    {"step_id": "p004", "description": "í›„ì† ì¡°ì¹˜ í™•ì •", "status": "done"}
                ],
                "optimization_logic": "íš¨ìœ¨ì ì¸ íšŒì˜ ì§„í–‰",
                "will": "ì²´ê³„ì ì¸ ì ˆì°¨ë¡œ ìƒì‚°ì ì¸ íšŒì˜ë¥¼ ìˆ˜í–‰í•œë‹¤"
            },
            "E": {
                "execution_plan": [
                    {
                        "action_id": "e001",
                        "description": f"ê²°ì •ì‚¬í•­ {len(decisions)}ê±´ ì‹¤í–‰",
                        "role": participants[0] if participants else "ë‹´ë‹¹ì",
                        "eta": "TBD"
                    }
                ],
                "tooling": ["íšŒì˜ì‹¤", "í™”ìƒíšŒì˜"],
                "edge_case_handling": ["ë¶ˆì°¸ ì‹œ íšŒì˜ë¡ ê³µìœ "],
                "will": "ê²°ì •ëœ ì‚¬í•­ì„ ì‹¤ì œë¡œ ì‹¤í–‰í•œë‹¤"
            },
            "R": {
                "reflection_notes": ["íšŒì˜ ì™„ë£Œ"],
                "lessons_learned": [],
                "success_path_inference": "ëª…í™•í•œ ê²°ì • â†’ ì‹¤í–‰ â†’ ì„±ê³¼",
                "future_prediction": "í›„ì† íšŒì˜ í•„ìš” ì—¬ë¶€ íŒë‹¨",
                "will": "íšŒì˜ ê²°ê³¼ë¥¼ ë˜ëŒì•„ë³´ê³  ê°œì„ ì ì„ ì°¾ëŠ”ë‹¤"
            },
            "T": {
                "impact_channels": ["ì°¸ì„ì", "ê´€ë ¨ íŒ€"],
                "traffic_model": "íšŒì˜ë¡ ê³µìœ  â†’ ì•¡ì…˜ ì‹¤í–‰",
                "viral_mechanics": "ê²°ì • ì‚¬í•­ì˜ íŒ€ ì „íŒŒ",
                "bottleneck_points": ["ì‹¤í–‰ ì§€ì—°"],
                "will": "íšŒì˜ ê²°ê³¼ë¥¼ ê´€ë ¨ìì—ê²Œ íš¨ê³¼ì ìœ¼ë¡œ ì „íŒŒí•œë‹¤"
            },
            "A": {
                "abstraction": "ë°˜ë³µ ê°€ëŠ¥í•œ íšŒì˜ í…œí”Œë¦¿í™”",
                "modularization": ["ì•ˆê±´ ëª¨ë“ˆ", "ê²°ì • ëª¨ë“ˆ", "íƒœìŠ¤í¬ ëª¨ë“ˆ"],
                "automation_opportunities": ["íšŒì˜ë¡ ìë™ ìƒì„±", "íƒœìŠ¤í¬ ìë™ ì¶”ì¶œ"],
                "integration_targets": [parent_id],
                "resonance_logic": f"ìƒìœ„ ëª©í‘œì™€ ì •ë ¬ (ì‹ ë¢°ë„: {confidence:.0%})",
                "will": "íšŒì˜ íŒ¨í„´ì„ ê³ ë„í™”í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì¸ë‹¤"
            },
            "links": {
                "parent": parent_id,
                "children": [],
                "related": [],
                "supersedes": None
            },
            "_parsed": {
                "decisions": decisions,
                "tasks": tasks,
                "agenda": agenda,
                "participants": participants,
                "confidence": confidence
            }
        }
        
        return holon
    
    def parse_and_create(self, text: str, auto_spawn: bool = True) -> dict:
        """íšŒì˜ë¡ íŒŒì‹± í›„ Holon íŒŒì¼ ìƒì„±"""
        print("=" * 60)
        print("ğŸ”¥ íšŒì˜ë¡ ìë™ íŒŒì‹± & Holon ìƒì„±")
        print("=" * 60)
        print()
        
        # Meeting Holon ìƒì„±
        print("ğŸ“ íšŒì˜ë¡ ë¶„ì„ ì¤‘...")
        holon = self._create_meeting_holon(text)
        
        meeting_id = holon["holon_id"]
        title = holon["meta"]["title"]
        parent_id = holon["links"]["parent"]
        confidence = holon["_parsed"]["confidence"]
        decisions = holon["_parsed"]["decisions"]
        tasks = holon["_parsed"]["tasks"]
        
        print(f"   ì œëª©: {title}")
        print(f"   ID: {meeting_id}")
        print(f"   ìƒìœ„ ì—°ê²°: {parent_id} (ì‹ ë¢°ë„: {confidence:.0%})")
        print(f"   ê²°ì • ì‚¬í•­: {len(decisions)}ê±´")
        print(f"   í• ì¼: {len(tasks)}ê±´")
        print()
        
        # _parsed ì œê±° í›„ ì €ì¥
        parsed_info = holon.pop("_parsed")
        
        # Meeting íŒŒì¼ ì €ì¥
        filename = f"{meeting_id}-{holon['slug']}.md"
        filepath = self.meetings_path / filename
        
        content = f"""```json
{json.dumps(holon, ensure_ascii=False, indent=2)}
```

---

# ğŸ“‹ {title}

## ì›ë³¸ íšŒì˜ë¡

{text}

---

## ìë™ ì¶”ì¶œ ì •ë³´

### ê²°ì • ì‚¬í•­
{chr(10).join(f"- {d}" for d in decisions) if decisions else "- (ì¶”ì¶œëœ ê²°ì • ì—†ìŒ)"}

### í• ì¼
{chr(10).join(f"- [ ] {t}" for t in tasks) if tasks else "- (ì¶”ì¶œëœ í• ì¼ ì—†ìŒ)"}

---

*ğŸ”¥ Self-Healing ëª¨ë“œë¡œ ìë™ ìƒì„±ë¨*
"""
        
        filepath.write_text(content, encoding="utf-8")
        print(f"âœ… Meeting ìƒì„±: {filepath}")
        
        result = {
            "meeting_id": meeting_id,
            "file": str(filepath),
            "parent": parent_id,
            "confidence": confidence,
            "decisions": decisions,
            "tasks": tasks,
            "spawned": []
        }
        
        # Decision/Task ìë™ ìƒì„±
        if auto_spawn and (decisions or tasks):
            print()
            print("ğŸš€ Decision/Task ìë™ ìƒì„± ì¤‘...")
            spawned = self._spawn_from_meeting(meeting_id, decisions, tasks)
            result["spawned"] = spawned
        
        print()
        print("=" * 60)
        print(f"ğŸ”¥ ì™„ë£Œ! Meeting + {len(result['spawned'])}ê°œ í•˜ìœ„ ë¬¸ì„œ ìƒì„±")
        print("=" * 60)
        
        return result
    
    def _spawn_from_meeting(self, meeting_id: str, decisions: List[str], tasks: List[str]) -> List[str]:
        """Meetingì—ì„œ Decision/Task ìƒì„±"""
        spawned = []
        today = datetime.now().strftime("%Y-%m-%d")
        year = datetime.now().strftime("%Y")
        
        # Decision ìƒì„±
        for i, decision in enumerate(decisions[:5], 1):  # ìµœëŒ€ 5ê°œ
            decision_id = f"decision-{year}-{len(list(self.decisions_path.glob('*.md'))) + i:03d}"
            
            decision_holon = {
                "holon_id": decision_id,
                "slug": decision[:20].replace(" ", "-").lower(),
                "type": "decision",
                "meta": {
                    "title": decision[:50],
                    "created_at": today,
                    "status": "active"
                },
                "W": {
                    "will": {
                        "drive": f"'{decision}'ì„ ì‹¤í–‰ì— ì˜®ê¸´ë‹¤"
                    }
                },
                "links": {
                    "parent": meeting_id,
                    "children": [],
                    "related": []
                }
            }
            
            filepath = self.decisions_path / f"{decision_id}.md"
            content = f"""```json
{json.dumps(decision_holon, ensure_ascii=False, indent=2)}
```

# âœ… {decision[:50]}

*{meeting_id}ì—ì„œ ìë™ ìƒì„±ë¨*
"""
            filepath.write_text(content, encoding="utf-8")
            spawned.append(decision_id)
            print(f"   âœ… Decision: {decision_id}")
        
        # Task ìƒì„±
        for i, task in enumerate(tasks[:5], 1):  # ìµœëŒ€ 5ê°œ
            task_id = f"task-{year}-{len(list(self.tasks_path.glob('*.md'))) + i:03d}"
            
            task_holon = {
                "holon_id": task_id,
                "slug": task[:20].replace(" ", "-").lower(),
                "type": "task",
                "meta": {
                    "title": task[:50],
                    "created_at": today,
                    "status": "pending"
                },
                "W": {
                    "will": {
                        "drive": f"'{task}'ë¥¼ ì™„ë£Œí•œë‹¤"
                    }
                },
                "links": {
                    "parent": meeting_id,
                    "children": [],
                    "related": []
                }
            }
            
            filepath = self.tasks_path / f"{task_id}.md"
            content = f"""```json
{json.dumps(task_holon, ensure_ascii=False, indent=2)}
```

# â¬œ {task[:50]}

- [ ] ì™„ë£Œ

*{meeting_id}ì—ì„œ ìë™ ìƒì„±ë¨*
"""
            filepath.write_text(content, encoding="utf-8")
            spawned.append(task_id)
            print(f"   â¬œ Task: {task_id}")
        
        return spawned


def main():
    """í…ŒìŠ¤íŠ¸ìš©"""
    sample = """
# 2025ë…„ AI íŠœí„° ê°œë°œ í‚¥ì˜¤í”„ íšŒì˜

ì¼ì‹œ: 2025-11-30
ì°¸ì„ì: ê¹€ì² ìˆ˜, ì´ì˜í¬, ë°•ë¯¼ìˆ˜

## ì•ˆê±´
1. AI íŠœí„° MVP ë²”ìœ„ í™•ì •
2. ê°œë°œ ì¼ì • ë…¼ì˜
3. ë‹´ë‹¹ì ë°°ì •

## ë…¼ì˜ ë‚´ìš©
í•™ìƒ ì§„ë‹¨ ê¸°ëŠ¥ì„ ë¨¼ì € ê°œë°œí•˜ê¸°ë¡œ í•¨.
ì‹œì„  ì¶”ì  ê¸°ëŠ¥ì€ 2ë‹¨ê³„ë¡œ ì§„í–‰.

## ê²°ì • ì‚¬í•­
- ê²°ì •: MVPëŠ” ì§„ë‹¨ ë¦¬í¬íŠ¸ ê¸°ëŠ¥ìœ¼ë¡œ í•œì •
- ê²°ì •: 2ì›” ë§ ë² íƒ€ ì¶œì‹œ ëª©í‘œ

## í• ì¼
- TODO: ê¹€ì² ìˆ˜ - UI ë””ìì¸ ì´ˆì•ˆ (12/15ê¹Œì§€)
- TODO: ì´ì˜í¬ - ë°±ì—”ë“œ API ì„¤ê³„
- ë°•ë¯¼ìˆ˜ ë‹´ë‹¹ - ë°ì´í„° ëª¨ë¸ ì„¤ê³„
"""
    
    parser = MeetingParser(str(Path(__file__).parent))
    result = parser.parse_and_create(sample)
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

